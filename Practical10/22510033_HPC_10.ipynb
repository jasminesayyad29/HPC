{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNZQjM0OKQ2BzLKHvzumma1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["**PS 1**\n","\n","Execute the following program and check the properties of your GPU."],"metadata":{"id":"VAnQp-xcUaCj"}},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xSnKshtMQkoB","executionInfo":{"status":"ok","timestamp":1762150148370,"user_tz":-330,"elapsed":33,"user":{"displayName":"Aadarsh Nandedkar","userId":"10428050164531060189"}},"outputId":"13a4593b-8521-458a-dcda-a6dd1c685882"},"outputs":[{"output_type":"stream","name":"stdout","text":["Writing deviceQuery.cu\n"]}],"source":["%%writefile deviceQuery.cu\n","#include <stdio.h>\n","#include <stdlib.h>\n","#include <cuda_runtime.h>\n","\n","int main()\n","{\n","    int deviceCount;\n","    cudaGetDeviceCount(&deviceCount);\n","    if (deviceCount == 0)\n","    {\n","        printf(\"There is no device supporting CUDA\\n\");\n","        return 0;\n","    }\n","    int dev;\n","    for (dev = 0; dev < deviceCount; ++dev)\n","    {\n","        cudaDeviceProp deviceProp;\n","        cudaGetDeviceProperties(&deviceProp, dev);\n","        if (dev == 0)\n","        {\n","            if (deviceProp.major < 1)\n","                printf(\"There is no device supporting CUDA.\\n\");\n","            else if (deviceCount == 1)\n","                printf(\"There is 1 device supporting CUDA\\n\");\n","            else\n","                printf(\"There are %d devices supporting CUDA\\n\", deviceCount);\n","        }\n","        printf(\"\\nDevice %d: \\\"%s\\\"\\n\", dev, deviceProp.name);\n","        printf(\"  Major revision number:                         %d\\n\", deviceProp.major);\n","        printf(\"  Minor revision number:                         %d\\n\", deviceProp.minor);\n","        printf(\"  Total amount of global memory:                 %zu bytes\\n\", deviceProp.totalGlobalMem);\n","        printf(\"  Total amount of constant memory:               %zu bytes\\n\", deviceProp.totalConstMem);\n","        printf(\"  Total amount of shared memory per block:       %zu bytes\\n\", deviceProp.sharedMemPerBlock);\n","        printf(\"  Total number of registers available per block: %d\\n\", deviceProp.regsPerBlock);\n","        printf(\"  Warp size:                                     %d\\n\", deviceProp.warpSize);\n","        printf(\"  Multiprocessor count:                          %d\\n\", deviceProp.multiProcessorCount);\n","        printf(\"  Maximum number of threads per block:           %d\\n\", deviceProp.maxThreadsPerBlock);\n","        printf(\"  Maximum sizes of each dimension of a block:    %d x %d x %d\\n\",\n","                deviceProp.maxThreadsDim[0], deviceProp.maxThreadsDim[1], deviceProp.maxThreadsDim[2]);\n","        printf(\"  Maximum sizes of each dimension of a grid:     %d x %d x %d\\n\",\n","                deviceProp.maxGridSize[0], deviceProp.maxGridSize[1], deviceProp.maxGridSize[2]);\n","        printf(\"  Maximum memory pitch:                          %zu bytes\\n\", deviceProp.memPitch);\n","        printf(\"  Texture alignment:                             %zu bytes\\n\", deviceProp.textureAlignment);\n","        printf(\"  Clock rate:                                    %d kilohertz\\n\", deviceProp.clockRate);\n","    }\n","    return 0;\n","}\n"]},{"cell_type":"code","source":["!nvidia-smi\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SnWwTsSiRTei","executionInfo":{"status":"ok","timestamp":1762150223297,"user_tz":-330,"elapsed":113,"user":{"displayName":"Aadarsh Nandedkar","userId":"10428050164531060189"}},"outputId":"547a12e5-8257-46ba-dfa9-6d1a135b169c"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Mon Nov  3 06:10:24 2025       \n","+-----------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n","|-----------------------------------------+------------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                        |               MIG M. |\n","|=========================================+========================+======================|\n","|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n","| N/A   55C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n","|                                         |                        |                  N/A |\n","+-----------------------------------------+------------------------+----------------------+\n","                                                                                         \n","+-----------------------------------------------------------------------------------------+\n","| Processes:                                                                              |\n","|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n","|        ID   ID                                                               Usage      |\n","|=========================================================================================|\n","|  No running processes found                                                             |\n","+-----------------------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["!nvcc deviceQuery.cu -o deviceQuery\n"],"metadata":{"id":"lDTFd2RqRoI-","executionInfo":{"status":"ok","timestamp":1762150154578,"user_tz":-330,"elapsed":1007,"user":{"displayName":"Aadarsh Nandedkar","userId":"10428050164531060189"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["!./deviceQuery\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QWB6BBSER0pg","executionInfo":{"status":"ok","timestamp":1762150156943,"user_tz":-330,"elapsed":126,"user":{"displayName":"Aadarsh Nandedkar","userId":"10428050164531060189"}},"outputId":"f2b7289c-262c-427c-8288-07e1467794a4"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["There is 1 device supporting CUDA\n","\n","Device 0: \"Tesla T4\"\n","  Major revision number:                         7\n","  Minor revision number:                         5\n","  Total amount of global memory:                 15828320256 bytes\n","  Total amount of constant memory:               65536 bytes\n","  Total amount of shared memory per block:       49152 bytes\n","  Total number of registers available per block: 65536\n","  Warp size:                                     32\n","  Multiprocessor count:                          40\n","  Maximum number of threads per block:           1024\n","  Maximum sizes of each dimension of a block:    1024 x 1024 x 64\n","  Maximum sizes of each dimension of a grid:     2147483647 x 65535 x 65535\n","  Maximum memory pitch:                          2147483647 bytes\n","  Texture alignment:                             512 bytes\n","  Clock rate:                                    1590000 kilohertz\n"]}]},{"cell_type":"markdown","source":["**PS 2**\n","\n","Write a program to where each thread prints its thread ID along with hello world. Lauch the kernel with one block and multiple threads."],"metadata":{"id":"cVTRyKfbUYKk"}},{"cell_type":"code","source":["!pip install cupy-cuda12x\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lJ07sJwqY7BG","executionInfo":{"status":"ok","timestamp":1762151187798,"user_tz":-330,"elapsed":3915,"user":{"displayName":"Aadarsh Nandedkar","userId":"10428050164531060189"}},"outputId":"4aeb0f78-3a91-404a-acd6-7f3dccd92827"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: cupy-cuda12x in /usr/local/lib/python3.12/dist-packages (13.3.0)\n","Requirement already satisfied: numpy<2.3,>=1.22 in /usr/local/lib/python3.12/dist-packages (from cupy-cuda12x) (1.26.4)\n","Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.12/dist-packages (from cupy-cuda12x) (0.8.3)\n"]}]},{"cell_type":"code","source":["import cupy as cp\n","\n","# Allocate space for messages (one per thread)\n","num_threads = 8\n","messages = cp.empty((num_threads,), dtype=cp.int32)\n","\n","# Define a CUDA kernel that stores thread IDs\n","kernel = cp.RawKernel(r'''\n","extern \"C\" __global__\n","void hello(int *out) {\n","    int tid = threadIdx.x;\n","    out[tid] = tid;\n","}\n","''', 'hello')\n","\n","# Launch kernel with 1 block and 8 threads\n","kernel((1,), (num_threads,), (messages,))\n","\n","# Copy back and print from host\n","cp.cuda.Stream.null.synchronize()\n","\n","for tid in messages.get():\n","    print(f\"Hello World from thread {tid}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_IGu9UN7ZtwQ","executionInfo":{"status":"ok","timestamp":1762151482397,"user_tz":-330,"elapsed":64,"user":{"displayName":"Aadarsh Nandedkar","userId":"10428050164531060189"}},"outputId":"da887dba-110b-4a0d-d078-704b2f69895d"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Hello World from thread 0\n","Hello World from thread 1\n","Hello World from thread 2\n","Hello World from thread 3\n","Hello World from thread 4\n","Hello World from thread 5\n","Hello World from thread 6\n","Hello World from thread 7\n"]}]},{"cell_type":"markdown","source":["**PS 3**\n","\n","Write a program to where each thread prints its thread ID along with hello world. Lauch the kernel with multiple blocks and multiple threads."],"metadata":{"id":"fFe_VTo5azjc"}},{"cell_type":"code","source":["import cupy as cp\n","\n","# Total configuration\n","threads_per_block = 4\n","num_blocks = 3\n","total_threads = threads_per_block * num_blocks\n","\n","# Allocate array to store thread IDs\n","messages = cp.empty((total_threads,), dtype=cp.int32)\n","\n","# Define CUDA kernel\n","kernel_code = r'''\n","extern \"C\" __global__\n","void hello(int *out) {\n","    int global_id = blockIdx.x * blockDim.x + threadIdx.x;\n","    out[global_id] = global_id;\n","}\n","'''\n","\n","# Compile kernel\n","hello_kernel = cp.RawKernel(kernel_code, 'hello')\n","\n","# Launch kernel with multiple blocks & threads\n","hello_kernel((num_blocks,), (threads_per_block,), (messages,))\n","\n","# Wait for GPU to finish\n","cp.cuda.Stream.null.synchronize()\n","\n","# Print output from host\n","for i, tid in enumerate(messages.get()):\n","    print(f\"Hello World from block {i // threads_per_block}, thread {i % threads_per_block}, global thread ID = {tid}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_rEr4KVWa2iz","executionInfo":{"status":"ok","timestamp":1762151592825,"user_tz":-330,"elapsed":56,"user":{"displayName":"Aadarsh Nandedkar","userId":"10428050164531060189"}},"outputId":"fe73204a-d287-47f5-815d-6457119adf3e"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Hello World from block 0, thread 0, global thread ID = 0\n","Hello World from block 0, thread 1, global thread ID = 1\n","Hello World from block 0, thread 2, global thread ID = 2\n","Hello World from block 0, thread 3, global thread ID = 3\n","Hello World from block 1, thread 0, global thread ID = 4\n","Hello World from block 1, thread 1, global thread ID = 5\n","Hello World from block 1, thread 2, global thread ID = 6\n","Hello World from block 1, thread 3, global thread ID = 7\n","Hello World from block 2, thread 0, global thread ID = 8\n","Hello World from block 2, thread 1, global thread ID = 9\n","Hello World from block 2, thread 2, global thread ID = 10\n","Hello World from block 2, thread 3, global thread ID = 11\n"]}]},{"cell_type":"markdown","source":["**PS 4**\n","\n","Write a program to where each thread prints its thread ID along with hello world. Lauch the kernel with 2D blocks and 2D threads."],"metadata":{"id":"7DsRSSnPbggx"}},{"cell_type":"code","source":["import cupy as cp\n","\n","# Define 2D grid and 2D block dimensions\n","threads_per_block = (3, 3)   # 3x3 threads = 9 threads per block\n","num_blocks = (2, 2)          # 2x2 blocks = 4 blocks total\n","\n","# Total threads = 4 blocks × 9 threads = 36\n","total_threads = num_blocks[0] * num_blocks[1] * threads_per_block[0] * threads_per_block[1]\n","\n","# Allocate output arrays\n","thread_ids = cp.empty((total_threads,), dtype=cp.int32)\n","\n","# CUDA kernel\n","kernel_code = r'''\n","extern \"C\" __global__\n","void hello2D(int *out) {\n","    int tx = threadIdx.x;\n","    int ty = threadIdx.y;\n","    int bx = blockIdx.x;\n","    int by = blockIdx.y;\n","    int bw = blockDim.x;\n","    int bh = blockDim.y;\n","    int gw = gridDim.x;\n","\n","    // Compute a unique global thread ID for 2D grid & block\n","    int global_id = ((by * gw + bx) * (bw * bh)) + (ty * bw + tx);\n","\n","    out[global_id] = global_id;\n","}\n","'''\n","\n","# Compile the kernel\n","hello2D_kernel = cp.RawKernel(kernel_code, 'hello2D')\n","\n","# Launch kernel (2D grid, 2D block)\n","hello2D_kernel(num_blocks, threads_per_block, (thread_ids,))\n","\n","# Wait for GPU to finish\n","cp.cuda.Stream.null.synchronize()\n","\n","# Print output\n","for gid in range(total_threads):\n","    bx = (gid // (threads_per_block[0] * threads_per_block[1])) % num_blocks[0]\n","    by = gid // ((threads_per_block[0] * threads_per_block[1]) * num_blocks[0])\n","    local_id = gid % (threads_per_block[0] * threads_per_block[1])\n","    tx = local_id % threads_per_block[0]\n","    ty = local_id // threads_per_block[0]\n","    print(f\"Hello World from Block ({bx}, {by}), Thread ({tx}, {ty}), Global Thread ID = {gid}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xWfbCfMBbfuz","executionInfo":{"status":"ok","timestamp":1762151776010,"user_tz":-330,"elapsed":76,"user":{"displayName":"Aadarsh Nandedkar","userId":"10428050164531060189"}},"outputId":"bf2aae35-eefe-437a-c24b-af395d710f0f"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Hello World from Block (0, 0), Thread (0, 0), Global Thread ID = 0\n","Hello World from Block (0, 0), Thread (1, 0), Global Thread ID = 1\n","Hello World from Block (0, 0), Thread (2, 0), Global Thread ID = 2\n","Hello World from Block (0, 0), Thread (0, 1), Global Thread ID = 3\n","Hello World from Block (0, 0), Thread (1, 1), Global Thread ID = 4\n","Hello World from Block (0, 0), Thread (2, 1), Global Thread ID = 5\n","Hello World from Block (0, 0), Thread (0, 2), Global Thread ID = 6\n","Hello World from Block (0, 0), Thread (1, 2), Global Thread ID = 7\n","Hello World from Block (0, 0), Thread (2, 2), Global Thread ID = 8\n","Hello World from Block (1, 0), Thread (0, 0), Global Thread ID = 9\n","Hello World from Block (1, 0), Thread (1, 0), Global Thread ID = 10\n","Hello World from Block (1, 0), Thread (2, 0), Global Thread ID = 11\n","Hello World from Block (1, 0), Thread (0, 1), Global Thread ID = 12\n","Hello World from Block (1, 0), Thread (1, 1), Global Thread ID = 13\n","Hello World from Block (1, 0), Thread (2, 1), Global Thread ID = 14\n","Hello World from Block (1, 0), Thread (0, 2), Global Thread ID = 15\n","Hello World from Block (1, 0), Thread (1, 2), Global Thread ID = 16\n","Hello World from Block (1, 0), Thread (2, 2), Global Thread ID = 17\n","Hello World from Block (0, 1), Thread (0, 0), Global Thread ID = 18\n","Hello World from Block (0, 1), Thread (1, 0), Global Thread ID = 19\n","Hello World from Block (0, 1), Thread (2, 0), Global Thread ID = 20\n","Hello World from Block (0, 1), Thread (0, 1), Global Thread ID = 21\n","Hello World from Block (0, 1), Thread (1, 1), Global Thread ID = 22\n","Hello World from Block (0, 1), Thread (2, 1), Global Thread ID = 23\n","Hello World from Block (0, 1), Thread (0, 2), Global Thread ID = 24\n","Hello World from Block (0, 1), Thread (1, 2), Global Thread ID = 25\n","Hello World from Block (0, 1), Thread (2, 2), Global Thread ID = 26\n","Hello World from Block (1, 1), Thread (0, 0), Global Thread ID = 27\n","Hello World from Block (1, 1), Thread (1, 0), Global Thread ID = 28\n","Hello World from Block (1, 1), Thread (2, 0), Global Thread ID = 29\n","Hello World from Block (1, 1), Thread (0, 1), Global Thread ID = 30\n","Hello World from Block (1, 1), Thread (1, 1), Global Thread ID = 31\n","Hello World from Block (1, 1), Thread (2, 1), Global Thread ID = 32\n","Hello World from Block (1, 1), Thread (0, 2), Global Thread ID = 33\n","Hello World from Block (1, 1), Thread (1, 2), Global Thread ID = 34\n","Hello World from Block (1, 1), Thread (2, 2), Global Thread ID = 35\n"]}]},{"cell_type":"markdown","source":["**PS 5**\n","\n","Vector Addition using CUDA\n","Problem Statement: Write a CUDA C program that performs element-wise addition of two vectors A and B of size N. The result of the addition should be stored in vector C.\n","Details:\n","•\tInitialize the vectors A and B with random numbers.\n","•\tThe output vector C[i] = A[i] + B[i], where i ranges from 0 to N-1.\n","•\tUse CUDA kernels to perform the computation in parallel.\n","•\tWrite the code for both serial (CPU-based) and parallel (CUDA-based) implementations.\n","•\tMeasure the execution time of both the serial and CUDA implementations for different values of N (e.g., N = 10^5, 10^6, 10^7).\n","Task:\n","•\tCalculate and report the speedup (i.e., the ratio of CPU execution time to GPU execution time)."],"metadata":{"id":"tZ6d1FWVb2IB"}},{"cell_type":"code","source":["%%writefile vectorAdd.cu\n","#include <stdio.h>\n","#include <stdlib.h>\n","#include <cuda.h>\n","#include <time.h>\n","#include <math.h>\n","\n","// CUDA kernel for vector addition\n","__global__ void vectorAdd(float *A, float *B, float *C, int N) {\n","    int i = blockIdx.x * blockDim.x + threadIdx.x;\n","    if (i < N)\n","        C[i] = A[i] + B[i];\n","}\n","\n","// CPU implementation\n","void vectorAddCPU(float *A, float *B, float *C, int N) {\n","    for (int i = 0; i < N; i++) {\n","        C[i] = A[i] + B[i];\n","    }\n","}\n","\n","// Initialize vectors\n","void initializeVectors(float *A, float *B, int N) {\n","    for (int i = 0; i < N; i++) {\n","        A[i] = (float)rand() / RAND_MAX;\n","        B[i] = (float)rand() / RAND_MAX;\n","    }\n","}\n","\n","int main() {\n","    int N_values[] = {100000, 1000000, 10000000};\n","    int num_cases = 3;\n","\n","    for (int c = 0; c < num_cases; c++) {\n","        int N = N_values[c];\n","        size_t size = N * sizeof(float);\n","\n","        printf(\"\\n=============================\\n\");\n","        printf(\"Vector Size: %d\\n\", N);\n","\n","        // Allocate host memory\n","        float *h_A = (float *)malloc(size);\n","        float *h_B = (float *)malloc(size);\n","        float *h_C_CPU = (float *)malloc(size);\n","        float *h_C_GPU = (float *)malloc(size);\n","\n","        initializeVectors(h_A, h_B, N);\n","\n","        // CPU computation\n","        clock_t start_cpu = clock();\n","        vectorAddCPU(h_A, h_B, h_C_CPU, N);\n","        clock_t end_cpu = clock();\n","        double cpu_time = ((double)(end_cpu - start_cpu)) / CLOCKS_PER_SEC;\n","\n","        // GPU computation\n","        float *d_A, *d_B, *d_C;\n","        cudaMalloc((void **)&d_A, size);\n","        cudaMalloc((void **)&d_B, size);\n","        cudaMalloc((void **)&d_C, size);\n","\n","        cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);\n","        cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);\n","\n","        int threadsPerBlock = 256;\n","        int blocksPerGrid = (N + threadsPerBlock - 1) / threadsPerBlock;\n","\n","        cudaEvent_t start_gpu, stop_gpu;\n","        cudaEventCreate(&start_gpu);\n","        cudaEventCreate(&stop_gpu);\n","\n","        cudaEventRecord(start_gpu);\n","        vectorAdd<<<blocksPerGrid, threadsPerBlock>>>(d_A, d_B, d_C, N);\n","        cudaEventRecord(stop_gpu);\n","\n","        cudaMemcpy(h_C_GPU, d_C, size, cudaMemcpyDeviceToHost);\n","        cudaEventSynchronize(stop_gpu);\n","\n","        float gpu_time = 0;\n","        cudaEventElapsedTime(&gpu_time, start_gpu, stop_gpu);\n","        gpu_time /= 1000.0;  // convert ms to seconds\n","\n","        // Verify correctness\n","        int correct = 1;\n","        for (int i = 0; i < N; i++) {\n","            if (fabs(h_C_CPU[i] - h_C_GPU[i]) > 1e-5) {\n","                correct = 0;\n","                break;\n","            }\n","        }\n","\n","        // Print results\n","        printf(\"CPU Time: %.6f s\\n\", cpu_time);\n","        printf(\"GPU Time: %.6f s\\n\", gpu_time);\n","        if (gpu_time > 0)\n","            printf(\"Speedup: %.2fx\\n\", cpu_time / gpu_time);\n","        else\n","            printf(\"Speedup: N/A\\n\");\n","\n","        printf(\"Result Verification: %s\\n\", correct ? \"SUCCESS ✅\" : \"FAIL ❌\");\n","\n","        // CSV-style output for graph plotting\n","        printf(\"CSV_RESULT,%d,%.6f,%.6f\\n\", N, cpu_time, gpu_time);\n","\n","        // Free memory\n","        free(h_A); free(h_B); free(h_C_CPU); free(h_C_GPU);\n","        cudaFree(d_A); cudaFree(d_B); cudaFree(d_C);\n","    }\n","\n","    return 0;\n","}\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b9zeylQqb4KU","executionInfo":{"status":"ok","timestamp":1762152427178,"user_tz":-330,"elapsed":39,"user":{"displayName":"Aadarsh Nandedkar","userId":"10428050164531060189"}},"outputId":"429e83d9-75c2-48cc-bd64-4efb130d89ef"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting vectorAdd.cu\n"]}]},{"cell_type":"code","source":["!nvcc -arch=sm_75 vectorAdd.cu -o vectorAdd\n","!./vectorAdd\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L4I95N4pcDey","executionInfo":{"status":"ok","timestamp":1762152465863,"user_tz":-330,"elapsed":2525,"user":{"displayName":"Aadarsh Nandedkar","userId":"10428050164531060189"}},"outputId":"797a536e-747c-4e80-f4db-e53b6a4ba04d"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=============================\n","Vector Size: 100000\n","CPU Time: 0.000547 s\n","GPU Time: 0.000128 s\n","Speedup: 4.28x\n","Result Verification: SUCCESS ✅\n","CSV_RESULT,100000,0.000547,0.000128\n","\n","=============================\n","Vector Size: 1000000\n","CPU Time: 0.005890 s\n","GPU Time: 0.000055 s\n","Speedup: 106.27x\n","Result Verification: SUCCESS ✅\n","CSV_RESULT,1000000,0.005890,0.000055\n","\n","=============================\n","Vector Size: 10000000\n","CPU Time: 0.045206 s\n","GPU Time: 0.000467 s\n","Speedup: 96.74x\n","Result Verification: SUCCESS ✅\n","CSV_RESULT,10000000,0.045206,0.000467\n"]}]},{"cell_type":"markdown","source":["**PS 6**\n","\n","Matrix Addition using CUDA\n","Problem Statement: Write a CUDA C program to perform element-wise addition of two matrices A and B of size M x N. The result of the addition should be stored in matrix C.\n","Details:\n","•\tInitialize the matrices A and B with random values.\n","•\tThe output matrix C[i][j] = A[i][j] + B[i][j] where i ranges from 0 to M-1 and j ranges from 0 to N-1.\n","•\tWrite code for both serial (CPU-based) and parallel (CUDA-based) implementations.\n","•\tMeasure the execution time of both implementations for various matrix sizes (e.g., 100x100, 500x500, 1000x1000).\n","Task:\n","•\tCalculate the speedup using the execution times of the CPU and GPU implementations."],"metadata":{"id":"4-EVV-iLedum"}},{"cell_type":"code","source":["%%writefile matrixAdd.cu\n","#include <stdio.h>\n","#include <stdlib.h>\n","#include <cuda.h>\n","#include <time.h>\n","#include <math.h>\n","\n","// CUDA kernel for matrix addition\n","__global__ void matrixAdd(float *A, float *B, float *C, int M, int N) {\n","    int row = blockIdx.y * blockDim.y + threadIdx.y;\n","    int col = blockIdx.x * blockDim.x + threadIdx.x;\n","    int idx = row * N + col;\n","\n","    if (row < M && col < N) {\n","        C[idx] = A[idx] + B[idx];\n","    }\n","}\n","\n","// CPU implementation of matrix addition\n","void matrixAddCPU(float *A, float *B, float *C, int M, int N) {\n","    for (int i = 0; i < M * N; i++) {\n","        C[i] = A[i] + B[i];\n","    }\n","}\n","\n","// Initialize matrices with random numbers\n","void initializeMatrices(float *A, float *B, int M, int N) {\n","    for (int i = 0; i < M * N; i++) {\n","        A[i] = (float)rand() / RAND_MAX;\n","        B[i] = (float)rand() / RAND_MAX;\n","    }\n","}\n","\n","int main() {\n","    int sizes[][2] = {{100,100}, {500,500}, {1000,1000}};\n","    int num_cases = 3;\n","\n","    for (int c = 0; c < num_cases; c++) {\n","        int M = sizes[c][0];\n","        int N = sizes[c][1];\n","        size_t size = M * N * sizeof(float);\n","\n","        printf(\"\\n=============================\\n\");\n","        printf(\"Matrix Size: %dx%d\\n\", M, N);\n","\n","        // Allocate host memory\n","        float *h_A = (float *)malloc(size);\n","        float *h_B = (float *)malloc(size);\n","        float *h_C_CPU = (float *)malloc(size);\n","        float *h_C_GPU = (float *)malloc(size);\n","\n","        // Initialize matrices\n","        initializeMatrices(h_A, h_B, M, N);\n","\n","        // --- CPU computation ---\n","        clock_t start_cpu = clock();\n","        matrixAddCPU(h_A, h_B, h_C_CPU, M, N);\n","        clock_t end_cpu = clock();\n","        double cpu_time = ((double)(end_cpu - start_cpu)) / CLOCKS_PER_SEC;\n","\n","        // --- GPU computation ---\n","        float *d_A, *d_B, *d_C;\n","        cudaMalloc((void **)&d_A, size);\n","        cudaMalloc((void **)&d_B, size);\n","        cudaMalloc((void **)&d_C, size);\n","\n","        cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);\n","        cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);\n","\n","        dim3 threadsPerBlock(16, 16);\n","        dim3 blocksPerGrid((N + threadsPerBlock.x - 1) / threadsPerBlock.x,\n","                           (M + threadsPerBlock.y - 1) / threadsPerBlock.y);\n","\n","        cudaEvent_t start_gpu, stop_gpu;\n","        cudaEventCreate(&start_gpu);\n","        cudaEventCreate(&stop_gpu);\n","\n","        cudaEventRecord(start_gpu);\n","        matrixAdd<<<blocksPerGrid, threadsPerBlock>>>(d_A, d_B, d_C, M, N);\n","        cudaEventRecord(stop_gpu);\n","\n","        cudaMemcpy(h_C_GPU, d_C, size, cudaMemcpyDeviceToHost);\n","        cudaEventSynchronize(stop_gpu);\n","\n","        float gpu_time = 0;\n","        cudaEventElapsedTime(&gpu_time, start_gpu, stop_gpu);\n","        gpu_time /= 1000.0; // convert ms → seconds\n","\n","        // Verify correctness\n","        int correct = 1;\n","        for (int i = 0; i < M * N; i++) {\n","            if (fabs(h_C_CPU[i] - h_C_GPU[i]) > 1e-5) {\n","                correct = 0;\n","                break;\n","            }\n","        }\n","\n","        // Print results\n","        printf(\"CPU Time: %.6f s\\n\", cpu_time);\n","        printf(\"GPU Time: %.6f s\\n\", gpu_time);\n","        if (gpu_time > 0)\n","            printf(\"Speedup: %.2fx\\n\", cpu_time / gpu_time);\n","        else\n","            printf(\"Speedup: N/A\\n\");\n","\n","        printf(\"Result Verification: %s\\n\", correct ? \"SUCCESS ✅\" : \"FAIL ❌\");\n","\n","        // CSV-style output for Python graph\n","        printf(\"CSV_RESULT,%d,%.6f,%.6f\\n\", M*N, cpu_time, gpu_time);\n","\n","        // Free memory\n","        free(h_A); free(h_B); free(h_C_CPU); free(h_C_GPU);\n","        cudaFree(d_A); cudaFree(d_B); cudaFree(d_C);\n","    }\n","\n","    return 0;\n","}\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KxbtHQf-egDU","executionInfo":{"status":"ok","timestamp":1762152565223,"user_tz":-330,"elapsed":37,"user":{"displayName":"Aadarsh Nandedkar","userId":"10428050164531060189"}},"outputId":"8a00a59c-07a6-41e3-caf0-3d7b02858ef4"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing matrixAdd.cu\n"]}]},{"cell_type":"code","source":["!nvcc -arch=sm_75 matrixAdd.cu -o matrixAdd\n","!./matrixAdd\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B6aZazfhemeS","executionInfo":{"status":"ok","timestamp":1762152585055,"user_tz":-330,"elapsed":1435,"user":{"displayName":"Aadarsh Nandedkar","userId":"10428050164531060189"}},"outputId":"53abd5b5-7f93-4ddb-b293-34eb40e8e8d3"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=============================\n","Matrix Size: 100x100\n","CPU Time: 0.000054 s\n","GPU Time: 0.000085 s\n","Speedup: 0.64x\n","Result Verification: SUCCESS ✅\n","CSV_RESULT,10000,0.000054,0.000085\n","\n","=============================\n","Matrix Size: 500x500\n","CPU Time: 0.001100 s\n","GPU Time: 0.000023 s\n","Speedup: 48.62x\n","Result Verification: SUCCESS ✅\n","CSV_RESULT,250000,0.001100,0.000023\n","\n","=============================\n","Matrix Size: 1000x1000\n","CPU Time: 0.004353 s\n","GPU Time: 0.000061 s\n","Speedup: 71.82x\n","Result Verification: SUCCESS ✅\n","CSV_RESULT,1000000,0.004353,0.000061\n"]}]},{"cell_type":"markdown","source":["**PS 7**\n","\n","Dot Product of Two Vectors using CUDA\n","Problem Statement: Write a CUDA C program to compute the dot product of two vectors A and B of size N. The dot product is defined as:\n","Details:\n","•\tInitialize the vectors A and B with random values.\n","•\tImplement the dot product calculation using both serial (CPU) and parallel (CUDA) approaches.\n","•\tMeasure the execution time for both implementations with different vector sizes (e.g., N = 10^5, 10^6, 10^7).\n","•\tUse atomic operations or shared memory reduction in the CUDA kernel to compute the final sum.\n","Task:\n","•\tCalculate and report the speedup for different vector sizes."],"metadata":{"id":"pLogzXNieyhi"}},{"cell_type":"code","source":["%%writefile dotProduct.cu\n","#include <stdio.h>\n","#include <stdlib.h>\n","#include <cuda.h>\n","#include <time.h>\n","#include <math.h>\n","\n","// CUDA kernel for dot product using atomicAdd\n","__global__ void dotProductKernel(float *A, float *B, float *C, int N) {\n","    __shared__ float cache[256];\n","    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n","    int cacheIndex = threadIdx.x;\n","\n","    float temp = 0;\n","    while (tid < N) {\n","        temp += A[tid] * B[tid];\n","        tid += blockDim.x * gridDim.x;\n","    }\n","\n","    // Each thread stores partial sum in shared memory\n","    cache[cacheIndex] = temp;\n","    __syncthreads();\n","\n","    // Parallel reduction within block\n","    int i = blockDim.x / 2;\n","    while (i != 0) {\n","        if (cacheIndex < i)\n","            cache[cacheIndex] += cache[cacheIndex + i];\n","        __syncthreads();\n","        i /= 2;\n","    }\n","\n","    // One thread per block adds partial sum to global memory\n","    if (cacheIndex == 0)\n","        atomicAdd(C, cache[0]);\n","}\n","\n","// CPU version of dot product\n","float dotProductCPU(float *A, float *B, int N) {\n","    float sum = 0.0f;\n","    for (int i = 0; i < N; i++) {\n","        sum += A[i] * B[i];\n","    }\n","    return sum;\n","}\n","\n","// Initialize vectors\n","void initializeVectors(float *A, float *B, int N) {\n","    for (int i = 0; i < N; i++) {\n","        A[i] = (float)rand() / RAND_MAX;\n","        B[i] = (float)rand() / RAND_MAX;\n","    }\n","}\n","\n","int main() {\n","    int N_values[] = {100000, 1000000, 10000000};\n","    int num_cases = 3;\n","\n","    for (int c = 0; c < num_cases; c++) {\n","        int N = N_values[c];\n","        size_t size = N * sizeof(float);\n","\n","        printf(\"\\n=============================\\n\");\n","        printf(\"Vector Size: %d\\n\", N);\n","\n","        // Allocate host memory\n","        float *h_A = (float *)malloc(size);\n","        float *h_B = (float *)malloc(size);\n","        initializeVectors(h_A, h_B, N);\n","\n","        // --- CPU computation ---\n","        clock_t start_cpu = clock();\n","        float cpu_result = dotProductCPU(h_A, h_B, N);\n","        clock_t end_cpu = clock();\n","        double cpu_time = ((double)(end_cpu - start_cpu)) / CLOCKS_PER_SEC;\n","\n","        // --- GPU computation ---\n","        float *d_A, *d_B, *d_C;\n","        float h_C = 0.0f;\n","\n","        cudaMalloc((void **)&d_A, size);\n","        cudaMalloc((void **)&d_B, size);\n","        cudaMalloc((void **)&d_C, sizeof(float));\n","\n","        cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);\n","        cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);\n","        cudaMemcpy(d_C, &h_C, sizeof(float), cudaMemcpyHostToDevice);\n","\n","        int threadsPerBlock = 256;\n","        int blocksPerGrid = (N + threadsPerBlock - 1) / threadsPerBlock;\n","\n","        cudaEvent_t start_gpu, stop_gpu;\n","        cudaEventCreate(&start_gpu);\n","        cudaEventCreate(&stop_gpu);\n","\n","        cudaEventRecord(start_gpu);\n","        dotProductKernel<<<blocksPerGrid, threadsPerBlock>>>(d_A, d_B, d_C, N);\n","        cudaEventRecord(stop_gpu);\n","\n","        cudaMemcpy(&h_C, d_C, sizeof(float), cudaMemcpyDeviceToHost);\n","        cudaEventSynchronize(stop_gpu);\n","\n","        float gpu_time = 0;\n","        cudaEventElapsedTime(&gpu_time, start_gpu, stop_gpu);\n","        gpu_time /= 1000.0; // convert ms → s\n","\n","        // Verify correctness\n","        int correct = fabs(cpu_result - h_C) / fabs(cpu_result) < 1e-5;\n","\n","        // Print results\n","        printf(\"CPU Result: %.6f\\n\", cpu_result);\n","        printf(\"GPU Result: %.6f\\n\", h_C);\n","        printf(\"CPU Time: %.6f s\\n\", cpu_time);\n","        printf(\"GPU Time: %.6f s\\n\", gpu_time);\n","        if (gpu_time > 0)\n","            printf(\"Speedup: %.2fx\\n\", cpu_time / gpu_time);\n","        else\n","            printf(\"Speedup: N/A\\n\");\n","\n","        // CSV-style output\n","        printf(\"CSV_RESULT,%d,%.6f,%.6f\\n\", N, cpu_time, gpu_time);\n","\n","        // Free memory\n","        free(h_A);\n","        free(h_B);\n","        cudaFree(d_A);\n","        cudaFree(d_B);\n","        cudaFree(d_C);\n","    }\n","    return 0;\n","}\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CuWoKiwKe1ph","executionInfo":{"status":"ok","timestamp":1762152772217,"user_tz":-330,"elapsed":66,"user":{"displayName":"Aadarsh Nandedkar","userId":"10428050164531060189"}},"outputId":"37eaf8b6-257f-41f2-aab6-15b4cb2a89df"},"execution_count":56,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting dotProduct.cu\n"]}]},{"cell_type":"code","source":["!nvcc -arch=sm_75 dotProduct.cu -o dotProduct\n","!./dotProduct\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wxD_smbqe7Zp","executionInfo":{"status":"ok","timestamp":1762152777131,"user_tz":-330,"elapsed":1818,"user":{"displayName":"Aadarsh Nandedkar","userId":"10428050164531060189"}},"outputId":"c9d40c26-949d-43a6-a01a-0baf7fd38b09"},"execution_count":57,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=============================\n","Vector Size: 100000\n","CPU Result: 25001.640625\n","GPU Result: 25001.757812\n","CPU Time: 0.000298 s\n","GPU Time: 0.000117 s\n","Speedup: 2.55x\n","CSV_RESULT,100000,0.000298,0.000117\n","\n","=============================\n","Vector Size: 1000000\n","CPU Result: 249990.375000\n","GPU Result: 250029.671875\n","CPU Time: 0.002922 s\n","GPU Time: 0.000116 s\n","Speedup: 25.18x\n","CSV_RESULT,1000000,0.002922,0.000116\n","\n","=============================\n","Vector Size: 10000000\n","CPU Result: 2471388.500000\n","GPU Result: 2500497.250000\n","CPU Time: 0.029231 s\n","GPU Time: 0.000991 s\n","Speedup: 29.49x\n","CSV_RESULT,10000000,0.029231,0.000991\n"]}]},{"cell_type":"markdown","source":["**PS 8**\n","\n","Matrix Multiplication using CUDA\n","Problem Statement: Write a CUDA C program to perform matrix multiplication. Given two matrices A (MxN) and B (NxP), compute the resulting matrix C (MxP) where:\n","Details:\n","•\tInitialize the matrices A and B with random values.\n","•\tWrite code for both serial (CPU-based) and parallel (CUDA-based) implementations.\n","•\tMeasure the execution time of both implementations for various matrix sizes (e.g., 100x100, 500x500, 1000x1000).\n","Task:\n","•\tCalculate the speedup by comparing the CPU and GPU execution times."],"metadata":{"id":"YztUANCNfjBE"}},{"cell_type":"code","source":["%%writefile matrixMul.cu\n","\n","#include <stdio.h>\n","#include <stdlib.h>\n","#include <cuda.h>\n","#include <time.h>\n","\n","// ======================\n","// CUDA Kernel for Matrix Multiplication\n","// ======================\n","__global__ void matrixMul(float *A, float *B, float *C, int M, int N, int P) {\n","    int row = blockIdx.y * blockDim.y + threadIdx.y;  // Row index\n","    int col = blockIdx.x * blockDim.x + threadIdx.x;  // Column index\n","\n","    if (row < M && col < P) {\n","        float sum = 0.0f;\n","        for (int k = 0; k < N; k++) {\n","            sum += A[row * N + k] * B[k * P + col];\n","        }\n","        C[row * P + col] = sum;\n","    }\n","}\n","\n","// ======================\n","// CPU Matrix Multiplication\n","// ======================\n","void matrixMulCPU(float *A, float *B, float *C, int M, int N, int P) {\n","    for (int i = 0; i < M; i++) {\n","        for (int j = 0; j < P; j++) {\n","            float sum = 0.0f;\n","            for (int k = 0; k < N; k++) {\n","                sum += A[i * N + k] * B[k * P + j];\n","            }\n","            C[i * P + j] = sum;\n","        }\n","    }\n","}\n","\n","// ======================\n","// Random Matrix Initialization\n","// ======================\n","void initializeMatrix(float *mat, int rows, int cols) {\n","    for (int i = 0; i < rows * cols; i++) {\n","        mat[i] = (float)rand() / RAND_MAX;\n","    }\n","}\n","\n","// ======================\n","// Main Function\n","// ======================\n","int main() {\n","    int sizes[][3] = {{100, 100, 100}, {500, 500, 500}, {1000, 1000, 1000}};\n","    int num_cases = 3;\n","\n","    for (int c = 0; c < num_cases; c++) {\n","        int M = sizes[c][0];\n","        int N = sizes[c][1];\n","        int P = sizes[c][2];\n","\n","        printf(\"\\n====================================\\n\");\n","        printf(\"Matrix Size: %dx%d x %dx%d\\n\", M, N, N, P);\n","\n","        size_t size_A = M * N * sizeof(float);\n","        size_t size_B = N * P * sizeof(float);\n","        size_t size_C = M * P * sizeof(float);\n","\n","        float *h_A = (float *)malloc(size_A);\n","        float *h_B = (float *)malloc(size_B);\n","        float *h_C_CPU = (float *)malloc(size_C);\n","        float *h_C_GPU = (float *)malloc(size_C);\n","\n","        initializeMatrix(h_A, M, N);\n","        initializeMatrix(h_B, N, P);\n","\n","        // -------------------------\n","        // CPU Computation\n","        // -------------------------\n","        clock_t start_cpu = clock();\n","        matrixMulCPU(h_A, h_B, h_C_CPU, M, N, P);\n","        clock_t end_cpu = clock();\n","        double cpu_time = ((double)(end_cpu - start_cpu)) / CLOCKS_PER_SEC;\n","\n","        // -------------------------\n","        // GPU Computation\n","        // -------------------------\n","        float *d_A, *d_B, *d_C;\n","        cudaMalloc((void **)&d_A, size_A);\n","        cudaMalloc((void **)&d_B, size_B);\n","        cudaMalloc((void **)&d_C, size_C);\n","\n","        cudaMemcpy(d_A, h_A, size_A, cudaMemcpyHostToDevice);\n","        cudaMemcpy(d_B, h_B, size_B, cudaMemcpyHostToDevice);\n","\n","        dim3 threadsPerBlock(16, 16);\n","        dim3 blocksPerGrid((P + threadsPerBlock.x - 1) / threadsPerBlock.x,\n","                           (M + threadsPerBlock.y - 1) / threadsPerBlock.y);\n","\n","        cudaEvent_t start_gpu, stop_gpu;\n","        cudaEventCreate(&start_gpu);\n","        cudaEventCreate(&stop_gpu);\n","\n","        cudaEventRecord(start_gpu);\n","        matrixMul<<<blocksPerGrid, threadsPerBlock>>>(d_A, d_B, d_C, M, N, P);\n","        cudaEventRecord(stop_gpu);\n","\n","        cudaMemcpy(h_C_GPU, d_C, size_C, cudaMemcpyDeviceToHost);\n","        cudaEventSynchronize(stop_gpu);\n","\n","        float gpu_time;\n","        cudaEventElapsedTime(&gpu_time, start_gpu, stop_gpu);\n","        gpu_time /= 1000.0f; // convert ms to seconds\n","\n","        // -------------------------\n","        // Verification\n","        // -------------------------\n","        for (int i = 0; i < M * P; i++) {\n","            if (fabs(h_C_CPU[i] - h_C_GPU[i]) > 1e-3) {\n","                break;\n","            }\n","        }\n","\n","        // -------------------------\n","        // Output Results\n","        // -------------------------\n","        printf(\"CPU Time: %.6f s\\n\", cpu_time);\n","        printf(\"GPU Time: %.6f s\\n\", gpu_time);\n","        if (gpu_time > 0)\n","            printf(\"Speedup: %.2fx\\n\", cpu_time / gpu_time);\n","\n","        // Free memory\n","        free(h_A);\n","        free(h_B);\n","        free(h_C_CPU);\n","        free(h_C_GPU);\n","        cudaFree(d_A);\n","        cudaFree(d_B);\n","        cudaFree(d_C);\n","    }\n","\n","    return 0;\n","}\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nabR-nLvfmBt","executionInfo":{"status":"ok","timestamp":1762153004112,"user_tz":-330,"elapsed":82,"user":{"displayName":"Aadarsh Nandedkar","userId":"10428050164531060189"}},"outputId":"9005d632-b583-494c-b72c-2e3d4884d53d"},"execution_count":62,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting matrixMul.cu\n"]}]},{"cell_type":"code","source":["!nvcc matrixMul.cu -o matrixMul\n","!./matrixMul\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RKud7S_zf8-D","executionInfo":{"status":"ok","timestamp":1762153013655,"user_tz":-330,"elapsed":6839,"user":{"displayName":"Aadarsh Nandedkar","userId":"10428050164531060189"}},"outputId":"06d3ea0a-dda7-4890-92b7-5bc3e1d70175"},"execution_count":63,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","====================================\n","Matrix Size: 100x100 x 100x100\n","CPU Time: 0.003075 s\n","GPU Time: 0.007389 s\n","Speedup: 0.42x\n","\n","====================================\n","Matrix Size: 500x500 x 500x500\n","CPU Time: 0.672368 s\n","GPU Time: 0.000002 s\n","Speedup: 269378.21x\n","\n","====================================\n","Matrix Size: 1000x1000 x 1000x1000\n","CPU Time: 4.623642 s\n","GPU Time: 0.000002 s\n","Speedup: 1852420.69x\n"]}]}]}